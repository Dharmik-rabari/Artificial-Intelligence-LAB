# -*- coding: utf-8 -*-
"""Week3(Portfolio).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MladKXQbuCMYMytwnH1i1urs9pUgVHqC
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd; import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline
#Setting display format to retina in matplotlib to see better quality images.
from IPython.display import set_matplotlib_formats

# Lines below are just to ignore warnings

from sklearn.datasets import load_iris
iris= load_iris()
print(iris.feature_names)
print(iris.target)

import pandas as pd

# Convert the iris dataset to a pandas dataframe
df = pd.DataFrame(iris.data, columns=iris.feature_names)

# Add the target variable to the dataframe
df['target'] = iris.target

# Print the first 5 rows of the dataframe
print(df.head())

##Separating features and the target
#Letâ€™s separate features and the target in X and y respectively.
X= df.loc[:, ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]
print(X)
Y=df['target']

print(df.shape)
print(df.info())
print(df.target.value_counts())

# split X and y into training and testing sets
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=16)

# import the class
from sklearn.linear_model import LogisticRegression

# instantiate the model (using the default parameters)
logreg = LogisticRegression(multi_class='ovr')

# fit the model with data
logreg.fit(X_train, y_train)

print("Training set score:", logreg.score(X_train, y_train))

#y_pred = logreg.predict(X_test)
y_pred = logreg.predict(X_test)

from sklearn import metrics

cnf_matrix = metrics.confusion_matrix(y_test, y_pred)
cnf_matrix

# import required modules
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

class_names=[0,1] # name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

from sklearn.metrics import classification_report
target_names = ['0', '1','2']
print(classification_report(y_test, y_pred, target_names=target_names))

logreg.predict_proba(X_test)[:3]

"""In this week's lab, we worked with iris datasset and logisitic regession model to classify flowers into three different species. We first checked the structure by loading the data and we then separated the features and the target values. In this we did not needed the preprcoessing as the dataset was already cleab and balanced. After that, we worked on splitting the data into the training and testing. Then the logistic regression model is trained in order to make it's performance better. It showed high accuracy on the training set that was around 84%. The class 0 what predicted perfectly as shown by the confusion matrix. We saw that many erros showed between the class 1 and 2 which clearly means that they are hard to separate. Classification also showed similar results which can tell us that the low precision and recall value of class 2 compared to class 0."""