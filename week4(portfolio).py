# -*- coding: utf-8 -*-
"""Week4(Portfolio).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TyWinSy-20UEvSuTrmZ8yNIDhMz3rWIH
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import regularizers
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
# Load the dataset
path="Diabetes_ANN.csv"
df = pd.read_csv(path)
df.head()

class_counts = df['Outcome'].value_counts()

# Display the result
print(class_counts)

# Separate features and target
X = df.drop(columns=['Outcome'])
y = df['Outcome']

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Build the ANN model
model = Sequential([

 Dense(16, activation='relu', input_shape=(X_train_scaled.shape[1],),
          kernel_regularizer=regularizers.l2(0.01)),
    Dropout(0.3),
    Dense(8, activation='relu', kernel_regularizer=regularizers.l2(0.01)),
    Dropout(0.3),
    Dense(1, activation='sigmoid')

   ])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Early stopping to prevent overfitting
early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stop], verbose=1)

plt.figure(figsize=(12, 5))

# Accuracy plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()


plt.tight_layout()
plt.show()

# Predict on test data
y_pred_prob = model.predict(X_test_scaled)
y_pred = (y_pred_prob > 0.5).astype("int32")


# Confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['No Diabetes', 'Diabetes'],
            yticklabels=['No Diabetes', 'Diabetes'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.tight_layout()
plt.show()

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

# Print evaluation metrics
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print("\nClassification Report:\n", report)

from google.colab import drive
drive.mount('/content/drive')

"""In this weeks lab we have worked with balanced diabetes dataset to build an Artificial neural network classsifer in the keras. First of all, we loaded the data and check the counts of the class, which showed that both diabetic and non-diabetic classes balanced properly. We then split the data in training and testing sets, after that we did standardization of the features with the help of standard scalar, an imporatant part for the neural networks. The model we have used has two hidden layers with the ReLU activation, L2 regularisation and dropout to reduce the overfitting and sigmoid layer for binary output. We also used earlt stopping on the basis of validation loss, this cause the training to stopped automatically when the model stopped improving. While the training was happening, it can be seen that the accuracy of the training and the validation was increasing gradually over the epochs. The model was evaluated, after the training, by a confusion matric and other metrics like accuracy, precision and recall. The accuracy of the test was around 0.76 with a bit of better performance on the non diabetic class. So it helped me learn more about the set up ad training of ANN classification. Along with that it also made me better understand the techniques to improve generalisation"""