# -*- coding: utf-8 -*-
"""Week2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gtOLJnqqCo8BlOuKYUpRErRuIOrtnU4w
"""

!pip -q install shap

import numpy as np
import pandas as pd
import shap
import matplotlib.pyplot as plt

from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Load diabetes regression dataset
diabetes = load_diabetes()

# Convert to DataFrame
df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)
df['target'] = diabetes.target

df.head()

X = df.drop(columns=['target'])
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print("MAE:", round(mae,2))
print("RMSE:", round(rmse,2))
print("RÂ²:", round(r2,2))

explainer = shap.Explainer(model, X_train)
shap_values = explainer(X_test)

# Summary plot
shap.summary_plot(shap_values, X_test)

# Bar plot (feature importance)
shap.plots.bar(shap_values)

i = 0
print("Actual value:", y_test.iloc[i])
print("Predicted value:", y_pred[i])

shap.plots.waterfall(shap_values[i])

"""Introduction:
In this week's portfolio we will be working on implementing a linear regression model with the help of using SHAP. We used the diabetes regression dataset by scikit-learn. It contains medical features and a continuous target value that represents disease progression. So, in this task we trained linear regression model and understood and explained how all the features contribute to the perfection of the model.

Method:
I first uploaded the dataset and converted it in a pandas DataFrame. The variable that we were targeting was the disease progression value. Talking about the other features, they were used as input variables. Then we split the data into training and testing sets before training a linear regression model using scikit-learn. We evaluated the model with the help of MAE,RMSE and R2 to measure prediction error and performance overall. Then we worked with SHAP library to compute SHAP values to test data. And this helped me understand global feature's importance and prediction of the individual.

Explaination of Results using SHAP:
The summary of the SHAP showed the features with the strongest influence on the predictions of the model in the dataset. The features that have with larger SHAP value showed bigger impact when increasing or decreasing the predicted disease progression. Apart from that, bar plot helped in seeing the important features by ranking them on the basis of average SHAP values. The waterfall plot show singel prediction by showing the contribution be it positive or negative from baseling to final output. The model became more transparent with the help of using SHAP, and understanding different features that influence the prediction.
"""
